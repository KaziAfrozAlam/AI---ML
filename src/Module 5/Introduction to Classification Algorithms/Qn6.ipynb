{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Title: Popular Classification Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Support Vector Machines (SVM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 1: Identify handwriting on checks and classify each letter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99        53\n",
      "           1       0.98      0.98      0.98        50\n",
      "           2       0.98      1.00      0.99        47\n",
      "           3       0.96      0.96      0.96        54\n",
      "           4       1.00      1.00      1.00        60\n",
      "           5       0.97      0.95      0.96        66\n",
      "           6       0.98      0.98      0.98        53\n",
      "           7       1.00      0.98      0.99        55\n",
      "           8       0.95      0.95      0.95        43\n",
      "           9       0.97      0.97      0.97        59\n",
      "\n",
      "    accuracy                           0.98       540\n",
      "   macro avg       0.98      0.98      0.98       540\n",
      "weighted avg       0.98      0.98      0.98       540\n",
      "\n",
      "Confusion Matrix:\n",
      " [[53  0  0  0  0  0  0  0  0  0]\n",
      " [ 0 49  0  0  0  0  0  0  1  0]\n",
      " [ 0  0 47  0  0  0  0  0  0  0]\n",
      " [ 0  0  1 52  0  1  0  0  0  0]\n",
      " [ 0  0  0  0 60  0  0  0  0  0]\n",
      " [ 0  0  0  1  0 63  1  0  0  1]\n",
      " [ 1  0  0  0  0  0 52  0  0  0]\n",
      " [ 0  0  0  0  0  0  0 54  0  1]\n",
      " [ 0  1  0  0  0  1  0  0 41  0]\n",
      " [ 0  0  0  1  0  0  0  0  1 57]]\n"
     ]
    }
   ],
   "source": [
    "# Write your code here\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "digits = datasets.load_digits()\n",
    "X = digits.data\n",
    "y = digits.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "svm = SVC(kernel='linear', random_state=42)\n",
    "svm.fit(X_train, y_train)\n",
    "\n",
    "y_pred = svm.predict(X_test)\n",
    "\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Task 2: Detect gender of a speaker based on voice data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      1.00      0.67         2\n",
      "           1       1.00      0.33      0.50         3\n",
      "\n",
      "    accuracy                           0.60         5\n",
      "   macro avg       0.75      0.67      0.58         5\n",
      "weighted avg       0.80      0.60      0.57         5\n",
      "\n",
      "Confusion Matrix:\n",
      " [[2 0]\n",
      " [2 1]]\n"
     ]
    }
   ],
   "source": [
    "# Write your code here\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "data = {\n",
    "    'Pitch': [150, 135, 120, 175, 160, 130, 140, 170, 125, 155, 145, 180, 110, 155],\n",
    "    'Tone': [20, 22, 18, 24, 21, 19, 20, 23, 17, 20, 21, 25, 16, 19],\n",
    "    'Gender': [0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "X = df[['Pitch', 'Tone']]\n",
    "y = df['Gender']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "svm = SVC(kernel='linear', random_state=42)\n",
    "svm.fit(X_train, y_train)\n",
    "\n",
    "y_pred = svm.predict(X_test)\n",
    "\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 3: Classify email topics based on content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.84      0.85       236\n",
      "           1       0.62      0.73      0.67       287\n",
      "           2       0.76      0.79      0.78       290\n",
      "           3       0.63      0.69      0.66       285\n",
      "           4       0.82      0.73      0.78       312\n",
      "           5       0.83      0.77      0.79       308\n",
      "           6       0.79      0.78      0.79       276\n",
      "           7       0.83      0.84      0.83       304\n",
      "           8       0.92      0.90      0.91       279\n",
      "           9       0.86      0.90      0.88       308\n",
      "          10       0.92      0.91      0.92       309\n",
      "          11       0.97      0.91      0.94       290\n",
      "          12       0.73      0.75      0.74       304\n",
      "          13       0.85      0.88      0.87       300\n",
      "          14       0.92      0.90      0.91       297\n",
      "          15       0.90      0.92      0.91       292\n",
      "          16       0.87      0.88      0.88       270\n",
      "          17       0.96      0.94      0.95       272\n",
      "          18       0.82      0.81      0.82       239\n",
      "          19       0.84      0.70      0.76       196\n",
      "\n",
      "    accuracy                           0.83      5654\n",
      "   macro avg       0.84      0.83      0.83      5654\n",
      "weighted avg       0.83      0.83      0.83      5654\n",
      "\n",
      "Confusion Matrix:\n",
      " [[199   2   0   0   0   0   0   0   0   2   0   0   0   1   3   5   0   1\n",
      "    3  20]\n",
      " [  0 210  19  16   2  16   3   3   1   3   0   0   8   3   2   0   0   0\n",
      "    1   0]\n",
      " [  1  18 230  16   6   9   4   1   0   0   0   0   2   1   2   0   0   0\n",
      "    0   0]\n",
      " [  0  18  17 197  12   8  10   2   1   0   1   0  16   3   0   0   0   0\n",
      "    0   0]\n",
      " [  0   9   8  30 229   2  10   2   0   2   1   0  15   2   1   0   0   0\n",
      "    1   0]\n",
      " [  1  28  13   9   2 236   1   1   0   2   1   1   5   3   3   0   0   2\n",
      "    0   0]\n",
      " [  0   4   6  20   6   1 216   8   2   3   0   0   9   0   1   0   0   0\n",
      "    0   0]\n",
      " [  0   7   2   1   5   1   8 254   6   2   1   0  11   3   0   0   1   0\n",
      "    2   0]\n",
      " [  0   2   0   0   1   0   6   8 252   2   2   0   2   1   0   0   0   0\n",
      "    3   0]\n",
      " [  0   1   1   0   2   0   1   4   0 276  13   0   1   2   1   1   0   2\n",
      "    2   1]\n",
      " [  0   3   0   0   1   2   2   4   0  13 282   0   0   1   0   0   0   0\n",
      "    1   0]\n",
      " [  1   5   2   0   1   3   0   1   1   1   1 264   2   2   1   0   2   0\n",
      "    3   0]\n",
      " [  0   6   2  23   6   2   9  11   3   4   0   1 229   5   1   0   1   1\n",
      "    0   0]\n",
      " [  1  10   1   0   2   1   1   3   2   0   1   0   5 265   1   0   2   0\n",
      "    5   0]\n",
      " [  1   8   1   0   1   3   0   3   1   1   1   1   4   2 267   1   1   1\n",
      "    0   0]\n",
      " [  4   2   0   0   0   1   0   1   0   3   0   0   2   2   0 269   0   3\n",
      "    0   5]\n",
      " [  0   1   1   1   1   0   2   0   0   4   0   3   0   4   2   0 238   0\n",
      "   12   1]\n",
      " [  2   1   0   0   0   0   0   0   1   1   1   1   2   2   0   1   2 255\n",
      "    3   0]\n",
      " [  2   1   0   0   1   1   1   0   3   2   0   2   1   5   2   2  21   1\n",
      "  194   0]\n",
      " [ 18   0   0   0   0   0   0   0   1   1   1   0   1   3   2  21   5   0\n",
      "    6 137]]\n"
     ]
    }
   ],
   "source": [
    "# Write your code here\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "newsgroups = fetch_20newsgroups(subset='all')\n",
    "\n",
    "vectorizer = TfidfVectorizer(stop_words='english', max_features=2000)\n",
    "X = vectorizer.fit_transform(newsgroups.data)\n",
    "y = newsgroups.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "svm = SVC(kernel='linear', random_state=42)\n",
    "svm.fit(X_train, y_train)\n",
    "\n",
    "y_pred = svm.predict(X_test)\n",
    "\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
